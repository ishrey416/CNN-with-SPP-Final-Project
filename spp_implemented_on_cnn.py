# -*- coding: utf-8 -*-
"""SPP Implemented on CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EMP3bs3Mtq8A4wcKn86txRqS9a5TGXdT

# Preprocessing
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import glob
import random 
import time
 
import torch
import torchvision
import torchvision.transforms as transforms
 
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F

import timeit

from google.colab import drive
drive.mount('/content/gdrive')

"""Ishan's Path: "/content/gdrive/.shortcut-targets-by-id/1dO9M2V5QqmhdjySPgoSNJEyca7qh3Mez/SPP Final Project"

Mihir's Path: "/content/gdrive/.shortcut-targets-by-id/1dO9M2V5QqmhdjySPgoSNJEyca7qh3Mez/SPP Final Project"

Ben's Path: "/content/gdrive/.shortcut-targets-by-id/1dO9M2V5QqmhdjySPgoSNJEyca7qh3Mez/SPP Final Project"
"""

import os
os.chdir("/content/gdrive/.shortcut-targets-by-id/1dO9M2V5QqmhdjySPgoSNJEyca7qh3Mez/SPP Final Project")

transform_CIFAR = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),                                  
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])
])

transform_train_CNN = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

transform_test_CNN = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor()
])

transform_train_SPP = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

transform_test_SPP = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

batch_size = 8

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
            download=True, transform=transform_CIFAR)
trainset_CNN = torchvision.datasets.Caltech101(root='/Caltech101', 
            download=True, transform=transform_train_CNN)
trainset_SPP = torchvision.datasets.Caltech101(root='/Caltech101', 
            download=True, transform=transform_train_SPP)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,
            shuffle=True, num_workers=2)
trainloader_CNN = torch.utils.data.DataLoader(trainset_CNN, batch_size=batch_size,
            shuffle=True, num_workers=2)
trainloader_SPP = torch.utils.data.DataLoader(trainset_SPP, batch_size=batch_size,
            shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
            download=True, transform=transform_CIFAR)
testset_CNN = torchvision.datasets.Caltech101(root='/Caltech101',
            download=True, transform=transform_test_CNN)
testset_SPP = torchvision.datasets.Caltech101(root='/Caltech101',
            download=True, transform=transform_test_SPP)

testloader = torch.utils.data.DataLoader(testset, batch_size=256,
            shuffle=False, num_workers=2)
testloader_CNN = torch.utils.data.DataLoader(testset_CNN, batch_size=batch_size,
            shuffle=False, num_workers=2)
testloader_SPP = torch.utils.data.DataLoader(testset_SPP, batch_size=batch_size,
            shuffle=False, num_workers=2)

"""Print some sample images, labels"""

import matplotlib.pyplot as plt
import numpy as np

def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


dataiter = iter(trainloader_CNN)
images, labels = dataiter.next()

imshow(torchvision.utils.make_grid(images))

print(labels)

"""# **Regular CNN Model Trained on CalTech101**

This model will be trained on a dataset that we transformed to make sizes consistent to make it easier for the original CNN model to train and classify images (as a limitation of a vanilla CNN implementation). We will train and test on both the datasets of CIFAR-100 and Caltech101 to later compare with our SPP Network

Here is the CNN using the Caltech dataset to train and test on:
"""

import torch.nn as nn
import torch.nn.functional as F

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(2704, 200)
        self.fc2 = nn.Linear(200, 150)
        self.fc3 = nn.Linear(150, 101)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 2704)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

net = CNN()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters())

def set_random_seed(seed):
     torch.manual_seed(seed)
     torch.cuda.manual_seed_all(seed)
     np.random.seed(seed)
     random.seed(seed)
     torch.backends.cudnn.deterministic = True
set_random_seed(0)

for epoch in range(5):

    print(f"Epoch #{epoch}:")
    start = timeit.default_timer()

    running_loss = 0.0
    for i, data in enumerate(trainloader_CNN, 0):
        inputs, labels = data

        optimizer.zero_grad()

        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 50 == 49:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 50))
            running_loss = 0.0

    end = timeit.default_timer()
    print(f"Time elapsed: {end-start}")
    print()

print('Finished Training')

correct = 0
total = 0

with torch.no_grad():
    for data in testloader_CNN:
        images, labels = data

        outputs = net(images)

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))

"""# **Regular CNN Trained on CIFAR-10**
(for comparison purposes)

"""

import torch.nn as nn
import torch.nn.functional as F


class CNN_Cifar(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 200)
        self.fc2 = nn.Linear(200, 87)
        self.fc3 = nn.Linear(87, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = CNN_Cifar()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters())

def set_random_seed(seed):
     torch.manual_seed(seed)
     torch.cuda.manual_seed_all(seed)
     np.random.seed(seed)
     random.seed(seed)
     torch.backends.cudnn.deterministic = True
set_random_seed(0)

for epoch in range(5):

    print(f"Epoch #{epoch+1}:")
    start = timeit.default_timer()

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data

        optimizer.zero_grad()

        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 50 == 49:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 50))
            running_loss = 0.0

    end = timeit.default_timer()
    print(f"Time elapsed: {end-start}")
    print()

print('Finished Training')

correct = 0
total = 0

with torch.no_grad():
    for data in testloader:
        images, labels = data
 
        outputs = net(images)

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))

"""# SPP-Incorporated Model Trained on CalTech101

This is our primary implementation that we will use to demonstrate the marked improvement in image classification when different-sized images are involved. We train and test our network on the CalTech101 dataset, and show the improved difference in comparison to the regular CNN.
"""

import matplotlib.pyplot as plt
import numpy as np

def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

images = [trainset_SPP.__getitem__(i)[0] for i in range(1)]
labels = [trainset_SPP.__getitem__(i)[1] for i in range(1)]

imshow(torchvision.utils.make_grid(images))

print(labels)

def spp_layer(self, previous_conv, num_sample, previous_conv_size, out_pool_size):

    for i in range(len(out_pool_size)):
        # get dims of spatial bins
        h_wid = int(np.ceil(previous_conv_size[0] / out_pool_size[i]))
        w_wid = int(np.ceil(previous_conv_size[1] / out_pool_size[i]))

        # if integer rounding from above leads to some cutoff edges, pad them
        h_pad = int(np.ceil( (h_wid*out_pool_size[i] - previous_conv_size[0] + 1)/2 ))
        w_pad = int(np.ceil( (w_wid*out_pool_size[i] - previous_conv_size[1] + 1)/2 ))
        # note: if the pad is too large, the bin will be blocked out; error will arise

        maxpool = nn.MaxPool2d((h_wid, w_wid), stride=(h_wid, w_wid), padding=(h_pad, w_pad))

        # get features from spatial bins
        x = maxpool(previous_conv)
        if(i == 0): # first pooling level
            spp = x.view(num_sample,-1)
        else: # subsequent pooling levels
            spp = torch.cat((spp,x.view(num_sample,-1)), 1)

    return spp

import torch.nn as nn
import torch.nn.functional as F

class SPP_CNN(nn.Module):
    def __init__(self):
        super(SPP_CNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(336, 250)
        self.fc2 = nn.Linear(250, 200)
        self.fc3 = nn.Linear(200, 101)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.conv2(x)

        x = spp_layer(self, previous_conv=x, num_sample=int(x.size(0)), \
            previous_conv_size=[int(x.size(2)),int(x.size(3))], out_pool_size=[4,2,1])
        
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

spp_net = SPP_CNN().cuda()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(spp_net.parameters())

def set_random_seed(seed):
     torch.manual_seed(seed)
     torch.cuda.manual_seed_all(seed)
     np.random.seed(seed)
     random.seed(seed)
     torch.backends.cudnn.deterministic = True
set_random_seed(0)

for epoch in range(5):

    print(f"Epoch #{epoch}:")
    start = timeit.default_timer()

    running_loss = 0.0

    num_elems = trainset_SPP.__len__()
    rand_indexes = np.random.permutation(range(num_elems))

    for i, elem_index in enumerate(rand_indexes):
        inputs = trainset_SPP.__getitem__(elem_index)[0]
        labels = trainset_SPP.__getitem__(elem_index)[1]

        inputs = torch.unsqueeze(inputs, 0).cuda()
        labels = torch.Tensor([labels]).long().cuda()

        optimizer.zero_grad()

        outputs = spp_net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        if i % 200 == 199:
            print('[%d, %5d] loss: %.3f' %
                  # (epoch + 1, i + 1, running_loss / 50))
                  (epoch + 1, i + 1, running_loss / 200))
            running_loss = 0.0

    end = timeit.default_timer()
    print(f"Time elapsed: {end-start}")
    print()

print('Finished Training')

correct = 0
total = 0

with torch.no_grad():

    for i in range(testset_SPP.__len__()):

        images = testset_SPP.__getitem__(i)[0]
        labels = testset_SPP.__getitem__(i)[1]

        images = torch.unsqueeze(images, 0).cuda()
        labels = torch.Tensor([labels]).long().cuda()

        outputs = spp_net(images)

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))

"""# SPP-Incorporated Model Trained on CIFAR-10"""

def spp_layer(self,previous_conv, num_sample, previous_conv_size, out_pool_size):

    for i in range(len(out_pool_size)):
         # get dims of spatial bins
        h_wid = int(np.ceil(previous_conv_size[0] / out_pool_size[i]))
        w_wid = int(np.ceil(previous_conv_size[1] / out_pool_size[i]))

        # if integer rounding from above leads to some cutoff edges, pad them
        h_pad = int(np.ceil( (h_wid*out_pool_size[i] - previous_conv_size[0] + 1)/2 ))
        w_pad = int(np.ceil( (w_wid*out_pool_size[i] - previous_conv_size[1] + 1)/2 ))
        # note: if the pad is too large, the bin will be blocked out; error will arise
        ## note: got error since kernel size is 3, padding is 2 --> zeroed padding

        maxpool = nn.MaxPool2d((h_wid, w_wid), stride=(h_wid, w_wid), padding=(0, 0))

        # get features from spatial bins
        x = maxpool(previous_conv)
        if(i == 0): # first pooling level
            spp = x.view(num_sample,-1)
        else: # subsequent pooling levels
            spp = torch.cat((spp,x.view(num_sample,-1)), 1)

    return spp

class SPP_Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(224, 200)
        self.fc2 = nn.Linear(200, 87)
        self.fc3 = nn.Linear(87, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.conv2(x)

        x = spp_layer(self, previous_conv=x, num_sample=int(x.size(0)), \
            previous_conv_size=[int(x.size(2)),int(x.size(3))], out_pool_size=[4,2,1])

        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = SPP_Net()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters())

import timeit

for epoch in range(5):

    print(f"epoch #{epoch+1}")
    start = timeit.default_timer()

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):

        optimizer.zero_grad()

        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 50 == 49:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 50))
            running_loss = 0.0

    end = timeit.default_timer()
    print(f"time elapsed:{end-start}\n")

print('Finished Training')

correct = 0
total = 0

with torch.no_grad():
    for data in testloader:
        images, labels = data

        outputs = net(images)

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))

### performs on-par with the regular CNN

"""# Testing different SPP Configurations
Using `out_pool_layer` = [8,4,2,1] to add another level to the spatial pyramidal pooling (previously [4,2,1])

Tested on the CIFAR-10 dataset


"""

def spp_layer(self,previous_conv, num_sample, previous_conv_size, out_pool_size):
    
    for i in range(len(out_pool_size)):
        # get dims of spatial bins
        h_wid = int(np.ceil(previous_conv_size[0] / out_pool_size[i]))
        w_wid = int(np.ceil(previous_conv_size[1] / out_pool_size[i]))

        # if integer rounding from above leads to some cutoff edges, pad them
        h_pad = int(np.ceil( (h_wid*out_pool_size[i] - previous_conv_size[0] + 1)/2 ))
        w_pad = int(np.ceil( (w_wid*out_pool_size[i] - previous_conv_size[1] + 1)/2 ))
        ## note: got error since kernel size is 3, padding is 2 --> zeroed padding

        maxpool = nn.MaxPool2d((h, w), stride=(h, w), padding=(0, 0))

        # get features from spatial bins
        x = maxpool(previous_conv)
        if(i == 0): # first pooling level
            spp = x.view(num_sample,-1)
        else: # subsequent pooling levels
            spp = torch.cat((spp,x.view(num_sample,-1)), 1)

    return spp

class SPP_Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(624, 200) # for pool levels [8,4,2,1]
        self.fc2 = nn.Linear(200, 87) 
        self.fc3 = nn.Linear(87, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        # x = self.pool(F.relu(self.conv2(x)))
        x = self.conv2(x)

        x = spp_layer(self, previous_conv=x, num_sample=int(x.size(0)), \
            previous_conv_size=[int(x.size(2)),int(x.size(3))], \
            out_pool_size=[8,4,2,1]) ## note: additional pooling level

        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = SPP_Net()

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters())

import timeit

for epoch in range(5):

    print(f"epoch #{epoch+1}")
    start = timeit.default_timer()

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):

        inputs, labels = data

        optimizer.zero_grad()

        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 50 == 49:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 50))
            running_loss = 0.0

    end = timeit.default_timer()
    print(f"time elapsed:{end-start}\n")

print('Finished Training')

correct = 0
total = 0

with torch.no_grad():
    for data in testloader:
        images, labels = data

        outputs = net(images)

        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))

### performs on par with regular CNN, and slightly better than SPP_Net with out_pool_size=[4,2,1]

"""# Conclusion


In conclusion, the SPP-incorporated CNN performed more effectively on the Caltech101 dataset compared to on the CIFAR10 dataset. Over the course of 5 epochs, the loss of the SPP CNN was consistently lower than that of the regular CNN, which resulted in a 10% difference in accuracy. This proves that transformations such as cropping or warping pale in comparison to the SPP-layer which gathers data of different dimensions to have a complete understanding of the image. However, such an improvement was not so clear on the CIFAR-10 dataset. From the results, we can say that the SPP CNN performs _at least as well as_ the regular CNN, if not better.



"""